{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "834376c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bmil12/anaconda3/envs/HIPL/lib/python3.8/site-packages/Cython/Distutils/old_build_ext.py:15: DeprecationWarning: dep_util is Deprecated. Use functions from setuptools instead.\n",
      "  from distutils.dep_util import newer, newer_group\n",
      "Warning: Mujoco-based envs failed to import. Set the environment variable D4RL_SUPPRESS_IMPORT_ERROR=1 to suppress this message.\n",
      "No module named 'mjrl'\n",
      "Warning: Flow failed to import. Set the environment variable D4RL_SUPPRESS_IMPORT_ERROR=1 to suppress this message.\n",
      "No module named 'flow'\n",
      "Warning: CARLA failed to import. Set the environment variable D4RL_SUPPRESS_IMPORT_ERROR=1 to suppress this message.\n",
      "No module named 'carla'\n",
      "pybullet build time: May 20 2022 19:44:17\n",
      "/home/bmil12/anaconda3/envs/HIPL/lib/python3.8/site-packages/ml_collections/config_flags/config_flags.py:19: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import time\n",
    "import gzip\n",
    "import platform\n",
    "from datetime import datetime\n",
    "\n",
    "if 'mac' in platform.platform():\n",
    "    pass\n",
    "else:\n",
    "    os.environ['MUJOCO_GL'] = 'egl'\n",
    "    if 'SLURM_STEP_GPUS' in os.environ:\n",
    "        os.environ['EGL_DEVICE_ID'] = os.environ['SLURM_STEP_GPUS']\n",
    "\n",
    "from absl import app, flags\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import flax\n",
    "from jaxrl_m.dataset import Dataset\n",
    "\n",
    "import tqdm\n",
    "\n",
    "from src import d4rl_utils, d4rl_ant, ant_diagnostics, viz_utils\n",
    "from src.agents import TempDATA as learner\n",
    "from src.dataset_utils import GCDataset\n",
    "\n",
    "from jaxrl_m.wandb import setup_wandb, default_wandb_config\n",
    "import wandb\n",
    "from jaxrl_m.evaluation import evaluate_with_trajectories, EpisodeMonitor, supply_rng\n",
    "\n",
    "from ml_collections import config_flags\n",
    "import pickle\n",
    "\n",
    "from src.utils import record_video, CsvLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25a3ce98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "matplotlib.use('Agg')\n",
    "from matplotlib import patches\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "from functools import partial\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "import gym\n",
    "import d4rl\n",
    "import numpy as np\n",
    "import functools as ft\n",
    "import math\n",
    "from jaxrl_m.dataset import Dataset\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "\n",
    "def get_canvas_image(canvas):\n",
    "    canvas.draw()\n",
    "    out_image = np.frombuffer(canvas.tostring_rgb(), dtype='uint8')\n",
    "    out_image = out_image.reshape(canvas.get_width_height()[::-1] + (3,))\n",
    "    return out_image\n",
    "\n",
    "\n",
    "def valid_goal_sampler(self, np_random):\n",
    "    valid_cells = []\n",
    "    goal_cells = []\n",
    "\n",
    "    for i in range(len(self._maze_map)):\n",
    "        for j in range(len(self._maze_map[0])):\n",
    "            if self._maze_map[i][j] in [0, 'r', 'g']:\n",
    "                valid_cells.append((i, j))\n",
    "\n",
    "    sample_choices = valid_cells\n",
    "    cell = sample_choices[np_random.choice(len(sample_choices))]\n",
    "    xy = self._rowcol_to_xy(cell, add_random_noise=True)\n",
    "\n",
    "    random_x = np.random.uniform(low=0, high=0.5) * 0.25 * self._maze_size_scaling\n",
    "    random_y = np.random.uniform(low=0, high=0.5) * 0.25 * self._maze_size_scaling\n",
    "\n",
    "    xy = (max(xy[0] + random_x, 0), max(xy[1] + random_y, 0))\n",
    "\n",
    "    return xy\n",
    "\n",
    "\n",
    "class GoalReachingAnt(gym.Wrapper):\n",
    "    def __init__(self, env_name):\n",
    "        self.env = gym.make(env_name)\n",
    "        self.env.env.env._wrapped_env.goal_sampler = ft.partial(valid_goal_sampler, self.env.env.env._wrapped_env)\n",
    "        self.observation_space = gym.spaces.Dict({\n",
    "            'observation': self.env.observation_space,\n",
    "            'goal': self.env.observation_space,\n",
    "        })\n",
    "        self.action_space = self.env.action_space\n",
    "\n",
    "    def step(self, action):\n",
    "        next_obs, r, done, info = self.env.step(action)\n",
    "\n",
    "        achieved = self.get_xy()\n",
    "        desired = self.target_goal\n",
    "        distance = np.linalg.norm(achieved - desired)\n",
    "        info['x'], info['y'] = achieved\n",
    "        info['achieved_goal'] = np.array(achieved)\n",
    "        info['desired_goal'] = np.copy(desired)\n",
    "        info['success'] = float(distance < 0.5)\n",
    "        done = 'TimeLimit.truncated' in info\n",
    "\n",
    "        return self.get_obs(next_obs), r, done, info\n",
    "\n",
    "    def get_obs(self, obs):\n",
    "        target_goal = obs.copy()\n",
    "        target_goal[:2] = self.target_goal\n",
    "        return dict(observation=obs, goal=target_goal)\n",
    "\n",
    "    def reset(self):\n",
    "        obs = self.env.reset()\n",
    "        return self.get_obs(obs)\n",
    "\n",
    "    def get_starting_boundary(self):\n",
    "        self = self.env.env.env\n",
    "        torso_x, torso_y = self._init_torso_x, self._init_torso_y\n",
    "        S = self._maze_size_scaling\n",
    "        return (0 - S / 2 + S - torso_x, 0 - S / 2 + S - torso_y), (\n",
    "        len(self._maze_map[0]) * S - torso_x - S / 2 - S, len(self._maze_map) * S - torso_y - S / 2 - S)\n",
    "\n",
    "    def XY(self, n=20):\n",
    "        bl, tr = self.get_starting_boundary()\n",
    "        X = np.linspace(bl[0] + 0.04 * (tr[0] - bl[0]), tr[0] - 0.04 * (tr[0] - bl[0]), n)\n",
    "        Y = np.linspace(bl[1] + 0.04 * (tr[1] - bl[1]), tr[1] - 0.04 * (tr[1] - bl[1]), n)\n",
    "\n",
    "        X, Y = np.meshgrid(X, Y)\n",
    "        states = np.array([X.flatten(), Y.flatten()]).T\n",
    "        return states\n",
    "\n",
    "    def four_goals(self):\n",
    "        self = self.env.env.env\n",
    "\n",
    "        valid_cells = []\n",
    "        goal_cells = []\n",
    "\n",
    "        for i in range(len(self._maze_map)):\n",
    "            for j in range(len(self._maze_map[0])):\n",
    "                if self._maze_map[i][j] in [0, 'r', 'g']:\n",
    "                    valid_cells.append(self._rowcol_to_xy((i, j), add_random_noise=False))\n",
    "\n",
    "        goals = []\n",
    "        goals.append(max(valid_cells, key=lambda x: -x[0] - x[1]))\n",
    "        goals.append(max(valid_cells, key=lambda x: x[0] - x[1]))\n",
    "        goals.append(max(valid_cells, key=lambda x: x[0] + x[1]))\n",
    "        goals.append(max(valid_cells, key=lambda x: -x[0] + x[1]))\n",
    "        return goals\n",
    "\n",
    "    def draw(self, ax=None):\n",
    "        if not ax: ax = plt.gca()\n",
    "        self = self.env.env.env\n",
    "        torso_x, torso_y = self._init_torso_x, self._init_torso_y\n",
    "        S = self._maze_size_scaling\n",
    "        for i in range(len(self._maze_map)):\n",
    "            for j in range(len(self._maze_map[0])):\n",
    "                struct = self._maze_map[i][j]\n",
    "                if struct == 1:\n",
    "                    rect = patches.Rectangle((j * S - torso_x - S / 2, i * S - torso_y - S / 2), S, S,\n",
    "                                             linewidth=1, edgecolor='none', facecolor='grey', alpha=1.0)\n",
    "\n",
    "                    ax.add_patch(rect)\n",
    "        ax.set_xlim(0 - S / 2 + 0.6 * S - torso_x, len(self._maze_map[0]) * S - torso_x - S / 2 - S * 0.6)\n",
    "        ax.set_ylim(0 - S / 2 + 0.6 * S - torso_y, len(self._maze_map) * S - torso_y - S / 2 - S * 0.6)\n",
    "        ax.axis('off')\n",
    "\n",
    "\n",
    "def get_env_and_dataset(env_name):\n",
    "    env = GoalReachingAnt(env_name)\n",
    "    dataset = d4rl.qlearning_dataset(env)\n",
    "    dataset['masks'] = 1.0 - dataset['terminals']\n",
    "    dataset['dones_float'] = 1.0 - np.isclose(np.roll(dataset['observations'], -1, axis=0),\n",
    "                                              dataset['next_observations']).all(-1)\n",
    "    dataset = Dataset.create(**dataset)\n",
    "    return env, dataset\n",
    "\n",
    "\n",
    "def plot_value(env, dataset, value_fn, fig, ax, N=20, random=False, title=None):\n",
    "    observations = env.XY(n=N)\n",
    "\n",
    "    if random:\n",
    "        base_observations = np.copy(dataset['observations'][np.random.choice(dataset.size, len(observations))])\n",
    "    else:\n",
    "        base_observation = np.copy(dataset['observations'][0])\n",
    "        base_observations = np.tile(base_observation, (observations.shape[0], 1))\n",
    "\n",
    "    base_observations[:, :2] = observations\n",
    "\n",
    "    values = value_fn(base_observations)\n",
    "\n",
    "    x, y = observations[:, 0], observations[:, 1]\n",
    "    x = x.reshape(N, N)\n",
    "    y = y.reshape(N, N)\n",
    "    values = values.reshape(N, N)\n",
    "    mesh = ax.pcolormesh(x, y, values, cmap='viridis')\n",
    "    env.draw(ax)\n",
    "\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "    fig.colorbar(mesh, cax=cax, orientation='vertical')\n",
    "\n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "\n",
    "\n",
    "def plot_policy(env, dataset, policy_fn, fig, ax, N=20, random=False, title=None):\n",
    "    observations = env.XY(n=N)\n",
    "\n",
    "    if random:\n",
    "        base_observations = np.copy(dataset['observations'][np.random.choice(dataset.size, len(observations))])\n",
    "    else:\n",
    "        base_observation = np.copy(dataset['observations'][0])\n",
    "        base_observations = np.tile(base_observation, (observations.shape[0], 1))\n",
    "\n",
    "    base_observations[:, :2] = observations\n",
    "\n",
    "    policies = policy_fn(base_observations)\n",
    "\n",
    "    x, y = observations[:, 0], observations[:, 1]\n",
    "    x = x.reshape(N, N)\n",
    "    y = y.reshape(N, N)\n",
    "\n",
    "    policy_x = policies[:, 0].reshape(N, N)\n",
    "    policy_y = policies[:, 1].reshape(N, N)\n",
    "    mesh = ax.quiver(x, y, policy_x, policy_y)\n",
    "    env.draw(ax)\n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "\n",
    "\n",
    "def plot_trajectories(env, dataset, trajectories, fig, ax, color_list=None):\n",
    "    if color_list is None:\n",
    "        from itertools import cycle\n",
    "        color_cycle = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "        color_list = cycle(color_cycle)\n",
    "\n",
    "    for color, trajectory in zip(color_list, trajectories):\n",
    "        obs = np.array(trajectory['observation'])\n",
    "        all_x = obs[:, 0]\n",
    "        all_y = obs[:, 1]\n",
    "        ax.scatter(all_x, all_y, s=5, c=color, alpha=0.02)\n",
    "        ax.scatter(all_x[-1], all_y[-1], s=50, c=color, marker='*', alpha=0.3)\n",
    "\n",
    "    env.draw(ax)\n",
    "\n",
    "\n",
    "def plot_line_trajectories(env, dataset, trajectories, fig, ax, color_list=None):\n",
    "    if color_list is None:\n",
    "        from itertools import cycle\n",
    "        color_cycle = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "        color_list = cycle(color_cycle)\n",
    "\n",
    "    for color, trajectory in zip(color_list, trajectories):\n",
    "        obs = np.array(trajectory['observation'])\n",
    "        all_x = obs[:, 0]\n",
    "        all_y = obs[:, 1]\n",
    "        ax.plot(all_x, all_y, color=color, linewidth=0.7)\n",
    "\n",
    "    env.draw(ax)\n",
    "\n",
    "\n",
    "def gc_sampling_adaptor(policy_fn):\n",
    "    def f(observations, *args, **kwargs):\n",
    "        return policy_fn(observations['observation'], observations['goal'], *args, **kwargs)\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def trajectory_image(env, dataset, trajectories, **kwargs):\n",
    "    fig = plt.figure(tight_layout=True)\n",
    "    canvas = FigureCanvas(fig)\n",
    "\n",
    "    plot_line_trajectories(env, dataset, trajectories, fig, plt.gca(), **kwargs)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    image = get_canvas_image(canvas)\n",
    "    plt.close(fig)\n",
    "    return image\n",
    "\n",
    "\n",
    "def value_image(env, dataset, value_fn):\n",
    "    fig = plt.figure(tight_layout=True)\n",
    "    canvas = FigureCanvas(fig)\n",
    "    plot_value(env, dataset, value_fn, fig, plt.gca())\n",
    "    image = get_canvas_image(canvas)\n",
    "    plt.close(fig)\n",
    "    return image\n",
    "\n",
    "\n",
    "def most_squarelike(n):\n",
    "    c = int(n ** 0.5)\n",
    "    while c > 0:\n",
    "        if n % c in [0, c - 1]:\n",
    "            return (c, int(math.ceil(n / c)))\n",
    "        c -= 1\n",
    "\n",
    "\n",
    "def make_visual(env, dataset, methods):\n",
    "    h, w = most_squarelike(len(methods))\n",
    "    gs = gridspec.GridSpec(h, w)\n",
    "\n",
    "    fig = plt.figure(tight_layout=True)\n",
    "    canvas = FigureCanvas(fig)\n",
    "\n",
    "    for i, method in enumerate(methods):\n",
    "        wi, hi = i % w, i // w\n",
    "        ax = fig.add_subplot(gs[hi, wi])\n",
    "        method(env, dataset, fig=fig, ax=ax)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    image = get_canvas_image(canvas)\n",
    "    plt.close(fig)\n",
    "    return image\n",
    "\n",
    "\n",
    "def gcvalue_image(env, dataset, value_fn):\n",
    "    base_observation = dataset['observations'][0]\n",
    "\n",
    "    point1, point2, point3, point4 = env.four_goals()\n",
    "    point3 = (32.75, 24.75)\n",
    "\n",
    "    fig = plt.figure(tight_layout=True)\n",
    "    canvas = FigureCanvas(fig)\n",
    "\n",
    "    points = [point1, point2, point3, point4]\n",
    "    for i, point in enumerate(points):\n",
    "        point = np.array(point)\n",
    "        ax = fig.add_subplot(2, 2, i + 1)\n",
    "\n",
    "        goal_observation = base_observation.copy()\n",
    "        goal_observation[:2] = point\n",
    "\n",
    "        plot_value(env, dataset, partial(value_fn, goal_observation), fig, ax)\n",
    "\n",
    "        ax.set_title('Goal: ({:.2f}, {:.2f})'.format(point[0], point[1]))\n",
    "        ax.scatter(point[0], point[1], s=50, c='red', marker='*')\n",
    "\n",
    "    image = get_canvas_image(canvas)\n",
    "    plt.close(fig)\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce41eba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "agent_name = 'TempDATA'\n",
    "env_name = 'antmaze-large-play-v2'\n",
    "\n",
    "save_dir = 'exp/'\n",
    "restore_path = None\n",
    "restore_epoch = None\n",
    "run_group = 'Debug'\n",
    "seed = 0\n",
    "eval_episodes = 50\n",
    "num_video_episodes = 2\n",
    "log_interval = 10000\n",
    "eval_interval = 100000\n",
    "save_interval = 1000000\n",
    "batch_size = 512\n",
    "rollout_batch_size = 256*30\n",
    "rollout_length = 3\n",
    "rollout_percent = 0.2\n",
    "train_steps = 1000000\n",
    "\n",
    "lr = 3e-4\n",
    "value_hidden_dim = 512\n",
    "value_num_layers = 3\n",
    "actor_hidden_dim = 512\n",
    "actor_num_layers = 3\n",
    "discount = 0.99\n",
    "tau = 0.005\n",
    "expectile = 0.95\n",
    "use_layer_norm = 1\n",
    "skill_dim = 32\n",
    "skill_expectile = 0.9\n",
    "skill_temperature = 1\n",
    "skill_discount = 0.99\n",
    "\n",
    "smoothing_coef = 0.01\n",
    "lp_ae = 1\n",
    "lp_mb = 1\n",
    "lp_rl = 1\n",
    "\n",
    "p_currgoal = 0.0\n",
    "p_trajgoal = 0.625\n",
    "p_randomgoal = 0.375\n",
    "\n",
    "planning_num_recursions = 0\n",
    "planning_num_states = 50000\n",
    "planning_num_knns = 50\n",
    "\n",
    "screenshot = 0\n",
    "encoder = None\n",
    "decoder = None\n",
    "p_aug = None\n",
    "\n",
    "algo_name = None  # Not used, only for logging\n",
    "\n",
    "# config_flags.DEFINE_config_dict('wandb', default_wandb_config(), lock_config=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4a15bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bmil12/anaconda3/envs/HIPL/lib/python3.8/site-packages/gym/spaces/box.py:84: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Goal:  (32.97065962507391, 25.122146318993995)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load datafile: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:01<00:00,  6.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Goal:  (33.35972718454154, 24.228173652309895)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load datafile: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:01<00:00,  6.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load from:  /home/bmil12/PycharmProjects/TempDATA/antmaze_aux/antmaze-large-play-v2-aux.npz\n"
     ]
    }
   ],
   "source": [
    "aux_env = {}\n",
    "goal_info = {}\n",
    "if 'antmaze' in env_name:\n",
    "    env_name = env_name\n",
    "\n",
    "    if 'ultra' in env_name:\n",
    "        import d4rl_ext\n",
    "        import gym\n",
    "        env = gym.make(env_name)\n",
    "        env = EpisodeMonitor(env)\n",
    "    else:\n",
    "        env = d4rl_utils.make_env(env_name)\n",
    "\n",
    "    dataset = d4rl_utils.get_dataset(env, env_name, goal_conditioned=True)\n",
    "    dataset = dataset.copy({'rewards': dataset['rewards'] - 1.0})\n",
    "\n",
    "    env.render(mode='rgb_array', width=200, height=200)\n",
    "    if 'ultra' in env_name:\n",
    "        env.viewer.cam.lookat[0] = 26\n",
    "        env.viewer.cam.lookat[1] = 18\n",
    "        env.viewer.cam.distance = 70\n",
    "        env.viewer.cam.elevation = -90\n",
    "\n",
    "    elif 'umaze' in env_name:\n",
    "        env.viewer.cam.lookat[0] = 6\n",
    "        env.viewer.cam.lookat[1] = 3\n",
    "        env.viewer.cam.distance = 40\n",
    "        env.viewer.cam.elevation = -90\n",
    "\n",
    "    elif 'medium' in env_name:\n",
    "        env.viewer.cam.lookat[0] = 10\n",
    "        env.viewer.cam.lookat[1] = 8\n",
    "        env.viewer.cam.distance = 50\n",
    "        env.viewer.cam.elevation = -90\n",
    "\n",
    "    elif 'large' in env_name:\n",
    "        env.viewer.cam.lookat[0] = 18\n",
    "        env.viewer.cam.lookat[1] = 12\n",
    "        env.viewer.cam.distance = 65\n",
    "        env.viewer.cam.elevation = -90\n",
    "\n",
    "    viz_env, viz_dataset = d4rl_ant.get_env_and_dataset(env_name)\n",
    "    viz = ant_diagnostics.Visualizer(env_name, viz_env, viz_dataset, discount=discount)\n",
    "    init_state = np.copy(viz_dataset['observations'][0])\n",
    "    init_state[:2] = (12.5, 8)\n",
    "    aux_env = {\n",
    "        'viz_env': viz_env,\n",
    "        'viz_dataset': viz_dataset,\n",
    "        'viz': viz,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3cba307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Goal:  (32.45636577796535, 25.353937391760372)\n",
      "Extra kwargs: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bmil12/anaconda3/envs/HIPL/lib/python3.8/site-packages/gym/utils/seeding.py:38: DeprecationWarning: \u001b[33mWARN: Function `rng.randn(*size)` is marked as deprecated and will be removed in the future. Please use `rng.standard_normal(size)` instead.\u001b[0m\n",
      "  deprecation(\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000000/1000000 [39:01<00:00, 427.05it/s]\n"
     ]
    }
   ],
   "source": [
    "base_observation = jax.tree_map(lambda arr: arr[0], dataset['observations'])\n",
    "env.reset()\n",
    "discrete = False\n",
    "\n",
    "train_dataset = GCDataset(\n",
    "    dataset,\n",
    "    p_currgoal=p_currgoal, p_trajgoal=p_trajgoal, p_randomgoal=p_randomgoal,\n",
    "    discount=discount, p_aug=p_aug,\n",
    ")\n",
    "\n",
    "total_steps = train_steps\n",
    "example_batch = dataset.sample(1)\n",
    "\n",
    "if 'procgen' in env_name:\n",
    "    discrete = True\n",
    "    example_action = np.max(dataset['actions'], keepdims=True)\n",
    "    print('===============================================')\n",
    "    print(example_action)\n",
    "    print(example_action.shape)\n",
    "    print('===============================================')\n",
    "\n",
    "agent = learner.create_learner(\n",
    "    seed,\n",
    "    example_batch['observations'],\n",
    "    example_batch['actions'] if not discrete else example_action,\n",
    "    lr=lr,\n",
    "    value_hidden_dims=(value_hidden_dim,) * value_num_layers,\n",
    "    actor_hidden_dims=(actor_hidden_dim,) * actor_num_layers,\n",
    "    discount=discount,\n",
    "    tau=tau,\n",
    "    expectile=expectile,\n",
    "    use_layer_norm=use_layer_norm,\n",
    "    skill_dim=skill_dim,\n",
    "    skill_expectile=skill_expectile,\n",
    "    skill_temperature=skill_temperature,\n",
    "    skill_discount=skill_discount,\n",
    "    rollout_length=rollout_length,\n",
    "    smoothing_coef=smoothing_coef,\n",
    "    encoder=encoder,\n",
    "    decoder=decoder,\n",
    "    discrete=discrete\n",
    ")\n",
    "\n",
    "rollout_fn = supply_rng(agent.sample_rollout)\n",
    "\n",
    "if restore_path is not None:\n",
    "    restore_path = restore_path\n",
    "    candidates = glob.glob(restore_path)\n",
    "    if len(candidates) == 0:\n",
    "        raise Exception(f'Path does not exist: {restore_path}')\n",
    "    if len(candidates) > 1:\n",
    "        raise Exception(f'Multiple matching paths exist for: {restore_path}')\n",
    "    if restore_epoch is None:\n",
    "        restore_path = candidates[0] + '/params.pkl'\n",
    "    else:\n",
    "        restore_path = candidates[0] + f'/params_{restore_epoch}.pkl'\n",
    "    with open(restore_path, \"rb\") as f:\n",
    "        load_dict = pickle.load(f)\n",
    "    agent = flax.serialization.from_state_dict(agent, load_dict['agent'])\n",
    "    print(f'Restored from {restore_path}')\n",
    "\n",
    "if 'antmaze' in env_name:\n",
    "    example_trajectory = train_dataset.sample(50, indx=np.arange(1000, 1050), evaluation=True)\n",
    "elif 'kitchen' in env_name:\n",
    "    example_trajectory = train_dataset.sample(50, indx=np.arange(0, 50))\n",
    "elif 'calvin' in env_name:\n",
    "    example_trajectory = train_dataset.sample(50, indx=np.arange(0, 50))\n",
    "elif 'procgen-500' in env_name:\n",
    "    example_trajectory = train_dataset.sample(50, indx=np.arange(5000, 5050))\n",
    "elif 'procgen-1000' in env_name:\n",
    "    example_trajectory = train_dataset.sample(50, indx=np.arange(5000, 5050))\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "train_logger = CsvLogger(os.path.join(save_dir, 'train.csv'))\n",
    "eval_logger = CsvLogger(os.path.join(save_dir, 'eval.csv'))\n",
    "first_time = time.time()\n",
    "last_time = time.time()\n",
    "\n",
    "agent_list = []\n",
    "for i in tqdm.tqdm(range(1, int(total_steps * lp_ae + 1)), smoothing=0.1, dynamic_ncols=True):\n",
    "    batch = train_dataset.sample(batch_size)\n",
    "    agent, update_info = agent.repr_update(batch)\n",
    "    \n",
    "    if i % 250000 == 0:\n",
    "        agent_list.append(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e64a2b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b516629",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_frame = env.render(mode='rgb_array', width=200, height=200)\n",
    "viz_env, viz_dataset, viz = aux_env['viz_env'], aux_env['viz_dataset'], aux_env['viz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9a0fdd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Goal:  (4.927227463529692, 8.960417542889838)\n"
     ]
    }
   ],
   "source": [
    "state = viz_env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f54f01",
   "metadata": {},
   "source": [
    "# TSNE plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2dfbd092",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(tight_layout=True)\n",
    "canvas = FigureCanvas(fig)\n",
    "ax = plt.gca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "730a94f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fd50727cfa0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs = state['observation']\n",
    "all_x = []\n",
    "all_y = []\n",
    "all_z = []\n",
    "\n",
    "viz_env.draw(ax)\n",
    "\n",
    "if 'medium' in env_name:\n",
    "    for i in np.arange(-1.9, 22.1, 0.5):\n",
    "        for j in np.arange(-1.9, 22.1, 0.5):\n",
    "            if -2 <= i <= 2 and 6 <= j <= 10:\n",
    "                pass\n",
    "            elif 6 <= i <= 14 and -2 <= j <= 2:\n",
    "                pass\n",
    "            elif 6 <= i <= 10 and 2 <= j <= 6:\n",
    "                pass\n",
    "            elif 14 <= i <= 22 and  6 <= j <= 10:\n",
    "                pass\n",
    "            elif 6 <= i <= 10 and 10 <= j <= 14:\n",
    "                pass\n",
    "            elif 2 <= i <= 6 and 14 <= j <= 18:\n",
    "                pass\n",
    "            elif 14 <= i <= 18 and 14 <= j <= 18:\n",
    "                pass\n",
    "            elif 10 <= i <= 14 and 18 <= j <= 22:\n",
    "                pass\n",
    "            else:\n",
    "                all_x.append(i)\n",
    "                all_y.append(j)\n",
    "                all_z.append(i+j)\n",
    "elif 'large' in env_name:\n",
    "    for i in np.arange(-1.9, 38.1, 0.5):\n",
    "        for j in np.arange(-1.9, 26.1, 0.5):\n",
    "            if -2 <= i <= 2 and 18 <= j <= 22:\n",
    "                pass\n",
    "            elif 2 <= i <= 10 and 2 <= j <= 6:\n",
    "                pass\n",
    "            elif 2 <= i <= 18 and 10 <= j <= 14:\n",
    "                pass\n",
    "            elif 6 <= i <= 10 and  14 <= j <= 26:\n",
    "                pass\n",
    "            elif 14 <= i <= 18 and 14 <= j <= 22:\n",
    "                pass\n",
    "            elif 14 <= i <= 18 and -2 <= j <= 6:\n",
    "                pass\n",
    "            elif 22 <= i <= 26 and 2 <= j <= 14:\n",
    "                pass\n",
    "            elif 26 <= i <= 34 and 10 <= j <= 14:\n",
    "                pass\n",
    "            elif 30 <= i <= 34 and 2 <= j <= 6:\n",
    "                pass\n",
    "            elif 30 <= i <= 38 and 18 <= j <= 22:\n",
    "                pass\n",
    "            elif 22 <= i <= 26 and 18 <= j <= 26:\n",
    "                pass\n",
    "            else:\n",
    "                all_x.append(i)\n",
    "                all_y.append(j)\n",
    "                all_z.append(i+j)\n",
    "\n",
    "ax.scatter(all_x, all_y, c=all_z, s = 5, marker='o', cmap='magma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a3b9a2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(f'{env_name}.pdf', format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c35a8725",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "from MulticoreTSNE import MulticoreTSNE as TSNE\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "93213479",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = np.stack([all_x, all_y], axis=1)\n",
    "states = np.concatenate([stack, np.repeat(state['observation'][2:].reshape(1, -1), stack.shape[0] ,axis=0)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "afa45737",
   "metadata": {},
   "outputs": [],
   "source": [
    "TSNE_staes = TSNE(n_jobs=4, n_components=2, n_iter=5000).fit_transform(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "83585abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "plt.scatter(TSNE_staes[:, 0], TSNE_staes[:, 1], c=all_z, s=5, marker='o', cmap='magma')\n",
    "plt.savefig(f'{date.today()}-{env_name}-state-TSNE.pdf', format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "073424af",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_id = 2\n",
    "representation = agent_list[agent_id].get_phi(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b7dceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 10000\n",
    "TSNE_repr = TSNE(n_jobs=4, n_components=2, n_iter=n_iter).fit_transform(representation)\n",
    "plt.scatter(TSNE_repr[:, 0], TSNE_repr[:, 1], c=all_z, s=5, marker='o', cmap='magma')\n",
    "# plt.savefig(f'{env_name}-representation-TSNE-{n_iter}-{smoothing_coef}-{date.today()}.pdf', format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e2e232",
   "metadata": {},
   "source": [
    "## Value Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fce224bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'large' in env_name:\n",
    "    for i in np.arange(-1.5, 38.1, 1):\n",
    "        for j in np.arange(-1.5, 26.1, 1):\n",
    "            if -2 <= i <= 2 and 18 <= j <= 22:\n",
    "                pass\n",
    "            elif 2 <= i <= 10 and 2 <= j <= 6:\n",
    "                pass\n",
    "            elif 2 <= i <= 18 and 10 <= j <= 14:\n",
    "                pass\n",
    "            elif 6 <= i <= 10 and  14 <= j <= 26:\n",
    "                pass\n",
    "            elif 14 <= i <= 18 and 14 <= j <= 22:\n",
    "                pass\n",
    "            elif 14 <= i <= 18 and -2 <= j <= 6:\n",
    "                pass\n",
    "            elif 22 <= i <= 26 and 2 <= j <= 14:\n",
    "                pass\n",
    "            elif 26 <= i <= 34 and 10 <= j <= 14:\n",
    "                pass\n",
    "            elif 30 <= i <= 34 and 2 <= j <= 6:\n",
    "                pass\n",
    "            elif 30 <= i <= 38 and 18 <= j <= 22:\n",
    "                pass\n",
    "            elif 22 <= i <= 26 and 18 <= j <= 26:\n",
    "                pass\n",
    "            else:\n",
    "                all_x.append(i)\n",
    "                all_y.append(j)\n",
    "                all_z.append(i+j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0cc3bd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = np.stack([all_x, all_y], axis=1)\n",
    "states = np.concatenate([stack, np.repeat(state['observation'][2:].reshape(1, -1), stack.shape[0] ,axis=0)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8b4112e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_x = 2\n",
    "goal_y = 2\n",
    "goal_stack = np.stack([[goal_x], [goal_y]], axis=1)\n",
    "goal_state = np.concatenate([goal_stack, state['observation'][2:].reshape(1, -1)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9133dc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "(v1, v2) = agent_list[2].network(states, goal_state, method='value') \n",
    "v = (v1 + v2) / 2\n",
    "normalized_v = (v - np.min(v)) / (np.max(v) - np.min(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4f5566b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(tight_layout=True)\n",
    "canvas = FigureCanvas(fig)\n",
    "ax = plt.gca()\n",
    "ax.scatter(all_x, all_y, c=normalized_v, s = 19, marker='s', cmap='viridis')\n",
    "plt.savefig(f'{env_name}-valuemap-{goal_x}-{goal_y}-{n_iter}-{smoothing_coef}-{date.today()}.pdf', format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb3cbd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
